#### University: [ITMO University](https://itmo.ru/ru/)
#### Faculty: [FTMI](https://ftmi.itmo.ru/)
#### Course: [Cloud platforms as the basis of technology entrepreneurship]
#### Year: 2023/2024
#### Group: U4225
#### Author: Lavrentev Nikita Yrievich
#### Lab: Lab2
#### Date of create: 25.10.2024
#### Date of finished: 31.10.2024

## Описание
Dторая лабораторная работа "Исследование Cloud Run"

## Цель работы
Ознакомиться с работой Cloud Run - это управляемая вычислительная платформа, которая позволяет запускать контейнеры (изолированная среда для приложения) непосредственно поверх масштабируемой инфраструктуры Google.

## Ход работы

# 1. Создал Cloud Run c дефолтным сервисом Hello на порту 8080 и задеплоил образ контейнера.

![image](https://github.com/user-attachments/assets/831bc69f-915a-4a66-912d-9eff8eff726c)
![image](https://github.com/user-attachments/assets/b2cff833-60c6-4c87-8104-954488e68357)

# 2. Проанализировал логи:

![image](https://github.com/user-attachments/assets/c97a5d19-1403-4318-83a1-e2ec2aaf5d1f)

В Cloud Run логи отображают информацию о запросах к контейнеру и событиях, происходящих внутри контейнера. В логах первой версии на порту 8080 можно было увидеть, что каждый запрос к сервису фиксировался в виде записи, где указаны:

IP-адрес клиента — источник запроса;
HTTP-метод и URI — показывают маршрут, по которому запрос пришел (например, корневой путь /);
Код ответа — подтверждает успешность обработки (например, код 200 указывает на успешный запрос);
Время ответа — служит индикатором производительности и стабильности.

# 3. Проанализировал метрики:

Среди метрик представлены следующие: количество запросов, задержка запросов, количество экзмепляров контейнера, оплачиваемое время экземпляра контейнера, загрузка ЦП контейнера, использование памяти котнейнера, количество отправленных и полученных байтов, максимальное количество одновременных запросов и задержка запуска контейнера.

Активность на отображаемых графиках метрик происходила за счет того, что я обращался к странице с информацией о запуске образа контейнера.

![image](https://github.com/user-attachments/assets/6723f9cd-e84e-4992-8cb6-5ceb7f169928)
![image](https://github.com/user-attachments/assets/778e3e57-273d-4c2f-be36-bdf6c6ab1ed3)
![image](https://github.com/user-attachments/assets/a70bf320-db59-4b02-acef-1f2f5280af41)


# 4. Далее создал новую версию на порту 8090 и задеплоил его. 

![image](https://github.com/user-attachments/assets/5890568c-9123-45c0-a67c-be34fef74f8a)
![image](https://github.com/user-attachments/assets/0342979f-8e4a-4e14-bdd7-556b8cccaf08)

# 5. Проанализировал логи х2:

![image](https://github.com/user-attachments/assets/028d935d-4481-42c9-a81d-a47f4db92ffc)

После перенастройки контейнера на порт 8090, в логах можно увидеть аналогичные данные.

# 6. Проанализировал метрики х2:
![image](https://github.com/user-attachments/assets/000afbea-beb7-4aa9-a257-da2bddf20159)
![image](https://github.com/user-attachments/assets/124d833b-6662-41ac-bc63-8747cf4eaba3)
![image](https://github.com/user-attachments/assets/5788c23a-6693-4017-bc61-56b3d5d05128)

1. Request Count (Количество запросов)
График показывает, что запросы поступали в контейнер в два различных промежутка времени, с небольшими паузами между ними.
2. Request Latencies (Задержка запросов)
Задержка оставалась стабильной и низкой на протяжении всего времени тестирования, около 10 миллисекунд, что говорит о высокой производительности и отсутствии проблем с задержкой.
Это может свидетельствовать о том, что приложение обрабатывает запросы быстро и эффективно, без значительных задержек или перегрузок на уровне сети или процессора.

# 7. в manage traffic начал тестировать распределение трафика:
    
90%/10%:

![image](https://github.com/user-attachments/assets/8cd189c2-95d8-407e-9048-75d92ba43002) 

Лог, показывающий распределение трафика:

![image_2024-10-31_23-28-08](https://github.com/user-attachments/assets/d1b34882-6aeb-48b9-ad88-62c845e5c4dd)

50%/50%:

>к сожалению скрин этого забыл сделать, sorryyy
Лог, показывающий распределение трафика:

![image_2024-11-01_00-01-15](https://github.com/user-attachments/assets/9e7f6fee-54e8-4539-bd05-f958e51cf64c)

Для того, чтобы проследить, как распределяется трафик между версиями, я обращался к сайту с информацией о запуске контейнера несколько раз

При распределении трафика 90%/10% больше трафика принимает на себя версия на порту 8080 (как раз на этой версии трафик распределялся в пропорции 90%), а при распределении трафика 50%/50% обе версии принимают на себя примерно одинаковое количестов трафика.

Это можно отследить с помощью отслеживание метрики "Количество запросов":

Распределение трафика 90%/10%:

![image](https://github.com/user-attachments/assets/f5b294ec-fa3e-4cb8-95bc-0d343293f803)

Распределение трафика 50%/50% - распределение трафика начинает уравниваться:

![image](https://github.com/user-attachments/assets/b7357314-e50f-411f-8fb8-37c1ce5721e6)

# 8. Удалил за собой все созданные сервисы

## Выводы
Лабораторная работа позволила закрепить навыки работы с облачной инфраструктурой Google, а также на практике изучить функции автоматического масштабирования и распределения трафика между версиями. Проведенное тестирование продемонстрировало, что Cloud Run является удобной и управляемой платформой для развертывания контейнеров, обеспечивая при этом гибкость и контроль за распределением ресурсов.
